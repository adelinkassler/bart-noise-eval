---
title: "R Notebook"
output: html_notebook
---

# Data

We'll start by loading in the data and taking a look at it. We just want to begin with one example data set, and then we can scale up the process from there (in a script of course).

## Load and format

We need both a practice level data set and a practice-year level data set. First, we load in the practice-year data.

```{r}
library(tidyverse)

project_root <- "/Users/daniel/Documents/Consulting/BCBS"
py_path <- "Data/track2_20220404/practice_year/acic_practice_year_0001.csv"
p_path <- "Data/track2_20220404/practice/acic_practice_0001.csv"

# reporting
.r <- function(.) { 
  message(sprintf("\nCreated tibble with %d rows and %d columns: %s", nrow(.),
                  ncol(.), paste(names(.), collapse = ', ')))
  invisible(.)
}

# Using base read.csv so we get stringsAsFactors
py0001.raw <- read.csv(file.path(project_root, py_path), stringsAsFactors = T) %>% .r
p0001.raw <- read.csv(file.path(project_root, p_path), stringsAsFactors = T) %>% .r

# Pivot years from rows to columns
# py0001.wide <- py0001.raw %>% 
#     pivot_wider(id_cols = c(id.practice, Z), 
#                 names_from = year, 
#                 values_from = c(Y, n.patients:V5_C_avg),
#                 names_glue = "{.value}.y{year}",
#                 names_prefix = "y") %>%
#     # Create new Y variable as weighted avg of last 2 years
#     mutate(Y_avg.post = (Y.y3 * n.patients.y3 + Y.y4 * n.patients.y4) /
#              (n.patients.y3 + n.patients.y4)) %>%
#     select(!c(Y.y3, Y.y4)) %>%
#     # Add differences between Y_y1, Y_y2
#     mutate(Y_diff.y1_y2 = Y.y2 - Y.y1)

# If you want lots of pairwise diffs, it's better to go long first and then wide
py0001.wide <- py0001.raw %>%
  pivot_longer(!c(id.practice, year, Z)) %>%
  group_by(id.practice, name) %>%
  arrange(id.practice, name, year) %>% 
  mutate(diff1 = value - lag(value),
         diff2 = value - lag(lag(value)),
         diff3 = value - lag(lag(lag(value)))) %>% 
  ungroup() %>%
  pivot_wider(id_cols = c(id.practice, Z),
              names_from = c(name, year),
              values_from = c(value, diff1, diff2, diff3),
              names_glue = "{name}{ifelse(.value=='value','','_diff')}.y{year}{ifelse(.value=='value','',paste0('_y',year-parse_number(.value,na='value')))}") %>% 
  select(!starts_with("post") & 
           !ends_with(c('0', '-1', '-2')) & 
           !starts_with(c("Y_diff.y3", "Y_diff.y4"))) %>% 
  mutate(Y_avg.post = (Y.y3 * n.patients.y3 + Y.y4 * n.patients.y4) /
           (n.patients.y3 + n.patients.y4)) %>%
  select(-Y.y4, -Y.y3) %>% 
  # rename(Y = Y_avg.post) %>%
  .r()

# # Testing the outcome
# mean(with(py0001.wide, V1_avg.y2 - V1_avg.y1 == V1_avg_diff.y2_y1))
# mean(with(py0001.wide, V1_avg.y3 - V1_avg.y1 == V1_avg_diff.y3_y1))
# mean(with(py0001.wide, n.patients.y2 - n.patients.y1 == n.patients_diff.y2_y1))
# mean(with(py0001.wide, n.patients.y3 - n.patients.y1 == n.patients_diff.y3_y1))

# Clean up
rm(py0001.raw)

```

## Merge to practice level

Then, we load in the practice level data set and merge it on according to the guidelines provided with the data. 

```{r}
# Merge by practice
py0001 <- inner_join(py0001.wide, p0001.raw, by = "id.practice")
py0001

# We're now done with the practice-level data frame
rm(p0001.raw, py0001.wide)

# BART package doesn't play well with class strings, so we need to fix
# class(py0001) <- c("data.frame", setdiff(class(py0001), "data.frame"))
class(py0001) <- 'data.frame'

```

<!---
What to know about this data:

-   **ID/grouping variables**: `id.practice`, `year`
-   **Treatment indicators**: `Z`, `post`
-   **Outcome**: `Y`
-   **Covariates**: `n.patients`, `V*_avg`, `X*`=
--->

## Assign noise variables

Next we write a function that assigns nuisance variables to a dataset.

```{r}
# Basic noise generating function - flexible distribution
generate_noise <- function(n, distr = "random", ..., verbose = FALSE) {

  if(distr == "random") {
    distr <- sample(c("rnorm", "rpois", "rexp", "rgamma", "rbinom"), 1)
  }

  args <- list(...)

  if(distr == "rnorm") {
    if(is.null(args$mean)) {
      mu <- rnorm(1, mean = 0, sd = 5)
    } else {
      mu <- args$mean
    }
    if(is.null(args$sd)) {
      sigma <- runif(1, min = 0.5, max = 5)
    } else {
      sigma <- args$sd
    }
    noise <- do.call(rnorm, c(list(n = n, mean = mu, sd = sigma)))
    
    if(verbose) {
      message(paste0("Generated noise from normal distribution with mean ", mu, " and sd ", sigma))
    }

  } else if(distr == "rpois") {
    if(is.null(args$lambda)) {
      lambda <- sample(1:10, 1) 
    } else {
      lambda <- args$lambda
    }
    noise <- do.call(rpois, c(list(n = n, lambda = lambda)))
    
    if(verbose) {
      message(paste0("Generated noise from Poisson distribution with lambda ", lambda)) 
    }

  } else if(distr == "rexp") {
    if(is.null(args$rate)) {
      rate <- runif(1, min = 0.1, max = 1)
    } else {
      rate <- args$rate
    }
    noise <- do.call(rexp, c(list(n = n, rate = rate)))
    
    if(verbose) {
      message(paste0("Generated noise from exponential distribution with rate ", rate))
    }

  } else if(distr == "rgamma") {
    if(is.null(args$shape)) {
      shape <- sample(1:5, 1)
    } else {
      shape <- args$shape
    }
    if(is.null(args$scale)) {
      scale <- runif(1, min = 0.5, max = 5)
    } else {
      scale <- args$scale
    }
    noise <- do.call(rgamma, c(list(n = n, shape = shape, scale = scale)))
    
    if(verbose) {
      message(paste0("Generated noise from gamma distribution with shape ", shape, " and scale ", scale))
    }

  } else if(distr == "rbinom") {
    if(is.null(args$size)) {
      trials <- sample(5:20, 1)
    } else {
      trials <- args$size
    }
    if(is.null(args$prob)) {
      prob <- runif(1, min = 0.1, max = 0.9)
    } else {
      prob <- args$prob
    }
    noise <- do.call(rbinom, c(list(n = n, size = trials, prob = prob)))
    
    if(verbose) {
      message(paste0("Generated noise from binomial distribution with trials ", trials, " and probability ", prob))
    }

  } else {
    stop(paste0("Don't know how to generate from function '", distr, "'. Please set distr to one of: random, rnorm, rpois, rexp, rgamma, rbinom"))
    
  }

  return(noise)

}

# Generate a bunch of noise variables in one go, and add them on to the dataset
add_noise_cols <- function(.data, num_vars, distr = "random", 
                           params = NULL, var_prefix = "noise_",
                           verbose = FALSE) {

  if(!is.data.frame(.data))
    stop(".data must be a data frame")

  if(length(num_vars) != 1 || !is.numeric(num_vars) || num_vars < 1)
    stop("num_vars must be a positive integer")

  if(!is.character(distr))
    stop("distr must be a character string specifying distribution type")

  if(!is.null(params)) {
    if(!is.list(params))
      stop("params must be a list")
    if(length(params) != num_vars)
      stop("Length of params must equal num_vars")
  }

  distr_params <- map(1:num_vars, ~list(distr = distr))
  
  if(!is.null(params)) {
    distr_params <- map2(distr_params, params, c)
  }

  noise_vars <- map(1:num_vars, function(i) {

    noise <- generate_noise(nrow(.data), distr_params[[i]], verbose)

    return(noise)

  })

  # Bind together results
  var_names <- paste0(var_prefix, 1:num_vars)
  names(noise_vars) <- var_names
  noise_df <- do.call(cbind, noise_vars)
  .data <- cbind(.data, noise_df)
  
  # Ensure correct typing to pass to BART function
  class(.data) <- c("data.frame", setdiff(class(.data), "data.frame"))

  return(.data)

}

```

Now using these functions, we add noise to the sample dataset we've uploaded. We'll create multiple versions of the dataset with different numbers of noise variables to see how performance changes.

```{r}
py0001.rnoise10 <- add_noise_cols(py0001, 10)
py0001.rnoise100 <- add_noise_cols(py0001, 100)
py0001.rnoise1000 <- add_noise_cols(py0001, 1000)
```

# Fitting BART/DART

Run BART and DART on the base data and modified noise data. We'll use functions from the `caret` package to cross validate. Bart doesn't need a train/validate split, so we don't need to hold out data to evaluate.

We'll also look at the run time for this expression.

## Run BART and DART (no cross val)

```{r, include=FALSE, cache=TRUE, eval=FALSE}
library(caret)
library(BART)

folds <- createFolds(py0001$Y_avg.post, k=10)
x_names <- setdiff(names(py0001), c("Y_avg.post", 'id.practice'))

# time.n0 <- system.time(bart.cv <- map(1:10, function(i) {
#   idx.test <- folds[[i]]
#   idx.train <- setdiff(1:nrow(py0001), idx.test)
#   
#   x.train <- py0001[idx.train, x_names]
#   y.train <- py0001[idx.train, 'Y_avg.post']
#   x.test <- py0001[idx.test, x_names]
#   y.test <- py0001[idx.test, 'Y_avg.post']
#   
#   # If this stage gives "Error in bartModelMatrix([...]): Expecting either a
#   # factor, a vector, a matrix or a data.frame", it probably means the class
#   # string for one of the data sets is in the wrong order. BART only reads the
#   # first element, so you need to reorder with one of those classes at the
#   # front.
#   py0001.bart <- gbart(x.train, y.train, x.test, sparse = F)
#   py0001.dart <- gbart(x.train, y.train, x.test, sparse = T)
#  
#   return(list(bart = py0001.bart, dart = py0001.dart))
#   
# }))

bart.fit <- gbart(py0001[x_names], py0001[['Y_avg.post']], sparse = F)
dart.fit <- gbart(py0001[x_names], py0001[['Y_avg.post']], sparse = T)

```



To get a sense for how timing changes, we'll also run this on the expanded data sets.

```{r, include=FALSE, cache=TRUE, eval=FALSE}
time.nx <- list()

bart.noisex.cv <- map(list(py0001.rnoise10, py0001.rnoise100, py0001.rnoise1000), function(.data) {
  x_names <- setdiff(names(.data), c("Y_avg.post", 'id.practice'))
  
  timing <- system.time(bart.cv <- map(1:10, function(i) {
    idx.test <- folds[[i]]
    idx.train <- setdiff(1:nrow(.data), idx.test)
    
    x.train <- .data[idx.train, x_names]
    y.train <- .data[idx.train, 'Y_avg.post']
    x.test <- .data[idx.test, x_names]
    y.test <- .data[idx.test, 'Y_avg.post']
    
    .data.bart <- gbart(x.train, y.train, x.test, sparse = F)
    .data.dart <- gbart(x.train, y.train, x.test, sparse = T)
    
    return(list(bart = .data.bart, dart = .data.dart))
    
  }))
  
  print(timing)
  try(time.nx <<- c(time.nx, list(timing)))
  
  return(bart.cv)
  
})

beepr::beep()

print(c(time.n0, time.nx))

```

Lastly, save our models for easy future loading, or load our models if we haven't generated them yet.. 

```{r}
if (exists('bart.cv')) {
  saveRDS(bart.cv, file = 'bartCV.rds')
} else {
  bart.cv <- readRDS('bartCV.rds')
}

if (exists('bart.noisex.cv')) {
  saveRDS(bart.noisex.cv, file = 'bartCVnoisex.rds')
} else {
  bart.noisex.cv <- readRDS('bartCVnoisex.rds')
}

```

# Performance

Now all we need to do is check performance using the eval metrics from ACIC. To do this, we need to implement partial dependence functions for the causal effect.

```{r}
pdep <- function(.model, .data) {
  newdata.z1 <- newdata.z0 <- .data %>% 
    select(!c(Y_avg.post, id.practice)) %>%
    bartModelMatrix()
  newdata.z0[,'Z'] <- 0
  newdata.z1[,'Z'] <- 1
  
  pred.z0 <- predict(.model, newdata.z0)
  pred.z1 <- predict(.model, newdata.z1)
  
  pred.diff <- pred.z1 - pred.z0
  return(pred.diff)
  
}

posterior_subgroup_avgs <- function(pred.diff, .data) {
  #pred.diff <- pdep(.model, .data)
  
  # Use total number of patients as weights
  n.patients <- .data %>% 
    select(starts_with("n.patients.y")) %>% 
    rowSums()  
browser()
  # Take the weighted average of subgroup
  # Returns a vector of length = # posterior draws
  return(apply(pred.diff, 1, function(.) weighted.mean(., n.patients)))
}

posterior_estimate <- function(pred.diff, .data) {
  pavg <- posterior_subgroup_avgs(pred.diff, .data)
  
  estimate <- mean(pavg)
  # Using a 90% credible interval
  interval <- quantile(pavg, c(.05, .95))
  
  #return(list(estimate = estimate, interval = interval))
  return(data.frame(est_satt = estimate, q05 = interval[[1]], q95 = interval[[2]]))
}

```

Get posterior estimates of each quantity of interest

```{r}
# post_est_subgroup_fn <- function(.name) {
#   function(.x) {
#     .data.sub <- .data %>% mutate(.idx = 1:nrow(.data)) %>% filter(id.practice == .x)
#     posterior_estimate(pred.diff[.data.sub$.idx, ], .data.sub) %>% 
#       select(-.idx) %>% 
#       mutate(id.practice = .x)
#   }
# }
# 
# .f <- function(.name) {
#   ..name <- ensym(.name)
#   filter(mtcars, !!..name == 1) %>% 
#     mutate(!!..name := -1)
# }
# .f('carb')


get_all_estimates <- function(pred.diff, .data) {
  ..data <- .data
  
  satt.overall <- posterior_estimate(pred.diff, ..data)
  
  satt.practice <- list_rbind(map(unique(..data$id.practice), function(.x) {
    ..data.sub <- ..data %>% mutate(.idx = 1:nrow(..data)) %>% filter(id.practice == .x)
    posterior_estimate(pred.diff[..data.sub$.idx, ], ..data.sub) %>% 
      select(-.idx) %>% 
      mutate(id.practice = .x)
    }))
  
  return(satt.practice)
  
  satt.levels <- list_rbind(map(1:5, function(.x)
    list_rbind(map(unique(..data[[paste0("X", .x)]]), function(.y) {
        ..data.sub <- ..data %>% 
          mutate(.idx = 1:nrow(..data)) %>% 
          filter(variable == paste0("X", .x), level == .y)
      posterior_estimate(pred.diff[..data.sub$.idx, ], ..data.sub) %>% 
        select(-.idx) %>% 
        mutate(variable = paste0("X", .x), level = .y)
    })) 
  ))
  
  return(satt.levels)

}

pdep_draws.test <- pdep(bart.fit, py0001)
test <- get_all_estimates(pdep_draws.test, py0001)
```


Now using the ground truth data, estimate performance of the model.

```{r, message=FALSE}
estimand_truths <- read_csv("Data/ACIC_estimand_truths.csv")

```



